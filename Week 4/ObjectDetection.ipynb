{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdASdbsY3GL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol5I54TXJRo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "## slim là package đi kèm với tensorflow, giúp định nghĩa nhanh các loại mô hình deep learning\n",
        "import tensorflow.contrib.slim as slim\n",
        "import tensorflow.contrib.slim.nets\n",
        "from tensorflow.contrib.slim.nets import vgg \n",
        "## sklearn là một thư viện rất phổ biến trong ML, chúng ta chỉ sử dụng tran_test_split để chia data thành 2 tập\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "## thư viện tính toán trên matrix\n",
        "import numpy as np\n",
        "import cv2\n",
        "# thư viện hiển thị biểu đồ\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj8SHdg4JRvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kích thước grid system \n",
        "cell_size = 7 \n",
        "# số boundary box cần dự đoán mỗi ô vuông\n",
        "box_per_cell = 2\n",
        "# kích thước ảnh đầu vào\n",
        "img_size = 224\n",
        "# số loại nhãn\n",
        "classes = {'circle':0, 'triangle':1,  'rectangle':2}\n",
        "nclass = len(classes)\n",
        "\n",
        "box_scale = 5.0\n",
        "noobject_scale = 0.5\n",
        "batch_size = 4\n",
        "# số lần huấn luyện\n",
        "epochs = 10\n",
        "# learning của chúng ta\n",
        "lr = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90CP4ivQZlun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load():\n",
        "    labels = json.load(open('/content/train/labels.json'))\n",
        "    # số lương ảnh\n",
        "    N = len(labels[:5000])\n",
        "    # matrix chứa ảnh\n",
        "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
        "    # matrix chứa nhãn của ảnh tương ứng\n",
        "    y = np.zeros((N,cell_size, cell_size, 5+nclass))\n",
        "    for idx, label in enumerate(labels[:5000]):\n",
        "        img = cv2.imread(\"train/{}.png\".format(idx))\n",
        "        # normalize về khoảng [0-1]\n",
        "        X[idx] = img\n",
        "        for box in label['boxes']:\n",
        "            x1, y1 = box['x1'], box['y1']\n",
        "            x2, y2 = box['x2'], box['y2']\n",
        "            # one-hot vector của nhãn object\n",
        "            cl = [0]*len(classes)\n",
        "            cl[classes[box['class']]] = 1\n",
        "            # tâm của boundary box\n",
        "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
        "            # index của object trên ma trận ô vuông 7x7\n",
        "            x_idx, y_idx = int(x_center/img_size*cell_size), int(y_center/img_size*cell_size)\n",
        "            # gán nhãn vào matrix \n",
        "            y[idx, y_idx, x_idx] = 1, x_center, y_center, w, h, *cl\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBX5fEz8aOMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget --quiet --no-check-certificate 'https://docs.google.com/uc?export=download&id=12sZLOe5VDvAqGHcjJh7mVmjB6HPeIEJh' -O train.zip\n",
        "! unzip -o -q train.zip\n",
        "! ls train | head"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BMrech8aRar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = load()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zitPLQSiaT7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg16(inputs, is_training):\n",
        "    \"\"\"định nghĩa CNN\n",
        "    Args:\n",
        "      inputs: 5-D tensor [batch_size, width, height, 3]\n",
        "    Return:\n",
        "      iou: 4-D tensor [batch_size, 7, 7, 5*nbox + nclass]\n",
        "    \"\"\"\n",
        "    # khái báo scope để có thê group những biến liên quan cho việc visualize trên tensorboard.\n",
        "    with tf.variable_scope(\"vgg_16\"):\n",
        "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
        "            # hàm repeat có tác dụng lặp lại tầng conv2d n lần mà không phải định nghĩa phức tạp. thank for slim package\n",
        "            net = slim.repeat(inputs, 2, slim.conv2d, 16, [3, 3], scope='conv1')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "            net = slim.repeat(net, 2, slim.conv2d, 32, [3, 3], scope='conv2')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "            net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
        "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
        "            \n",
        "            # thay vì sử dụng 2 tầng fully connected tại đây, \n",
        "            # chúng ta sử dụng conv với kernel_size = (1,1) có tác dụng giống hệt tầng fully conntected\n",
        "            net = slim.conv2d(net, 512, [1, 1], scope='fc6')   \n",
        "\n",
        "            net = slim.conv2d(net, 13, [1, 1], activation_fn=None, scope='fc7')\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4PJMxlLaiTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_iou(boxes1, boxes2, scope='iou'):\n",
        "    \"\"\"calculate ious\n",
        "    Args:\n",
        "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
        "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
        "    Return:\n",
        "      iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(scope):\n",
        "        # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
        "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
        "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
        "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
        "                             boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
        "                            axis=-1)\n",
        "\n",
        "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
        "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
        "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
        "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
        "                            axis=-1)\n",
        "\n",
        "        # calculate the left up point & right down point\n",
        "        lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
        "        rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
        "\n",
        "        # intersection\n",
        "        intersection = tf.maximum(0.0, rd - lu)\n",
        "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
        "\n",
        "        # calculate the boxs1 square and boxs2 square\n",
        "        square1 = boxes1[..., 2] * boxes1[..., 3]\n",
        "        square2 = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
        "\n",
        "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSddVSBPaiuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_layer(predicts, labels, scope='loss_layer'):\n",
        "    \"\"\"calculate loss function\n",
        "    Args:\n",
        "      predicts: 4-D tensor [batch_size, 7, 7, 5*nbox+n_class] \n",
        "      labels: 4-D tensor [batch_size, 7, 7, 5+n_class]\n",
        "    Return:\n",
        "      loss: scalar\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(scope):\n",
        "        offset = np.transpose(np.reshape(np.array(\n",
        "            [np.arange(cell_size)] * cell_size * box_per_cell),\n",
        "            (box_per_cell, cell_size, cell_size)), (1, 2, 0))\n",
        "        offset = offset[None, :]\n",
        "        offset = tf.constant(offset, dtype=tf.float32)\n",
        "        offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
        "        \n",
        "        # 2 phần tử đầu của vector dự đoán tại một ô vuông là confidence score\n",
        "        predict_object = predicts[..., :box_per_cell]\n",
        "        \n",
        "        # 8 phần tử tiếp theo là dự đoán offset của boundary box và width height\n",
        "        predict_box_offset = tf.reshape(predicts[...,box_per_cell:5*box_per_cell], (-1, cell_size, cell_size, box_per_cell, 4))\n",
        "        \n",
        "        # các phần tử cuối là dự đoán lớp của object\n",
        "        predict_class = predicts[...,5*box_per_cell:]\n",
        "        \n",
        "        # chuyển vị trí offset về toạ độ normalize trên khoảng [0-1]\n",
        "        predict_normalized_box = tf.stack(\n",
        "                                    [(predict_box_offset[..., 0] + offset) / cell_size,\n",
        "                                     (predict_box_offset[..., 1] + offset_tran) / cell_size,\n",
        "                                     tf.square(predict_box_offset[..., 2]),\n",
        "                                    tf.square(predict_box_offset[..., 3])], axis=-1)\n",
        "\n",
        "        # lấy các nhãn tương ứng \n",
        "        true_object = labels[..., :1]\n",
        "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
        "        \n",
        "        # để normalize tọa độ pixel về đoạn [0-1] chúng ta chia cho img_size (224)\n",
        "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
        "        true_class = labels[..., 5:]\n",
        "        \n",
        "        # tính vị trí offset từ nhãn \n",
        "        true_box_offset =  tf.stack(\n",
        "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
        "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
        "                                     tf.sqrt(true_normalized_box[..., 2]),\n",
        "                                     tf.sqrt(true_normalized_box[..., 3])], axis=-1)\n",
        "        \n",
        "        # tính iou\n",
        "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
        "        \n",
        "        # mask chứa vị trí các ô vuông chứa object\n",
        "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)  \n",
        "        \n",
        "        # tính metric để monitor \n",
        "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/tf.reduce_sum(true_object, axis=[1,2,3]))\n",
        "        \n",
        "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)*true_object\n",
        "\n",
        "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
        "        \n",
        "        ## class loss\n",
        "        class_delta = true_object*(predict_class - true_class)\n",
        "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
        "        \n",
        "        ## object loss\n",
        "        object_delta = object_mask*(predict_object - predict_iou)\n",
        "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
        "        \n",
        "        ## noobject loss\n",
        "        noobject_delta = noobject_mask*predict_object\n",
        "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
        "        \n",
        "        ## coord loss\n",
        "        box_mask = tf.expand_dims(object_mask, 4)\n",
        "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
        "        box_loss = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
        "        \n",
        "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
        "        \n",
        "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSOU6SJQal7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():    \n",
        "    # None đại diện cho batch_size, giúp batch_size có thể thay đổi linh hoạt\n",
        "    images = tf.placeholder(\"float\", [None, img_size, img_size, 3], name=\"input\")\n",
        "    labels = tf.placeholder('float', [None, cell_size, cell_size, 8], name='label')\n",
        "    is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "    logits = vgg16(images, is_training)\n",
        "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
        "    \n",
        "    # định nghĩa adam optimizer, để tối ưu hàm loss\n",
        "    optimizer = tf.train.AdamOptimizer(lr)\n",
        "    train_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qXglp-aaoBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session(graph=graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # định nghĩa saver để lưu lại trọng số của mô hình, dùng trong test các ảnh mới\n",
        "    saver = tf.train.Saver(max_to_keep=1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        for batch in range(len(X_train)//batch_size):\n",
        "            # lấy từng batch, forward, backward, cập nhật trọng số theo adam optimizer\n",
        "            X_batch = X_train[batch*batch_size:(batch+1)*batch_size]\n",
        "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
        "            train_total_loss, train_iou_m,_ = sess.run([loss, iou_metric, train_op], {images:X_batch, labels:y_batch, is_training:True})            \n",
        "        end_time = time.time()\n",
        "        \n",
        "        # tính toán loss, iou trên tập validation\n",
        "        val_loss = []\n",
        "        val_iou_ms = [] \n",
        "        for batch in range(len(X_test)//batch_size):\n",
        "            val_X_batch = X_test[batch*batch_size:(batch+1)*batch_size]\n",
        "            val_y_batch = y_test[batch*batch_size:(batch+1)*batch_size]\n",
        "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], \n",
        "                                                 {images:val_X_batch, labels:val_y_batch, is_training:False})\n",
        "            val_loss.append(total_val_loss)\n",
        "            val_iou_ms.append(val_iou_m)\n",
        "            \n",
        "        saver.save(sess, './model/yolo', global_step=epoch)\n",
        "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2v14nuVarHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iou(box1, box2):\n",
        "    \"\"\" tính iou bằng numpy \n",
        "    Args:\n",
        "      box1: [center_x, center_y, w, h] \n",
        "      box2: [center_x, center_y, w, h] \n",
        "    Return:\n",
        "      iou: iou\n",
        "    \"\"\"\n",
        "    tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n",
        "        max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n",
        "    lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n",
        "        max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n",
        "    inter = 0 if tb < 0 or lr < 0 else tb * lr\n",
        "    return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n",
        "    \n",
        "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
        "    # nhận lại img-size để ra không gian pixel\n",
        "    predict_box= predict_normalized_box*img_size\n",
        "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
        "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
        "    # xác suất ô boundary chứa class bằng boundary chứa object * xác suất có điều kiện của lớp đó mà ô vuông chứa object\n",
        "    class_probs = predict_object*predict_class\n",
        "    \n",
        "    # giữ các boundary box mà có xác suất chứa lớp >= 0.2\n",
        "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
        "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
        "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
        "    class_probs_filtered = class_probs[filter_mat_probs]\n",
        "    \n",
        "    # chọn index của lớp có xác xuất lớp nhất lại mỗi boundary box\n",
        "    classes_num_filtered = np.argmax(\n",
        "        filter_mat_probs, axis=3)[\n",
        "        filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
        "\n",
        "    # giữ lại boundary box dự đoán có xác xuất lớp nhất\n",
        "    argsort = np.array(np.argsort(class_probs_filtered))[::-1]\n",
        "    boxes_filtered = boxes_filtered[argsort]\n",
        "    class_probs_filtered = class_probs_filtered[argsort]\n",
        "    classes_num_filtered = classes_num_filtered[argsort]\n",
        "\n",
        "    # thuật toán non-maximun suppression\n",
        "    for i in range(len(boxes_filtered)):\n",
        "        if class_probs_filtered[i] == 0:\n",
        "            continue\n",
        "        for j in range(i + 1, len(boxes_filtered)):\n",
        "            if iou(boxes_filtered[i], boxes_filtered[j]) > 0.5:\n",
        "                class_probs_filtered[j] = 0.0\n",
        "                \n",
        "    # filter bước cuối bỏ những boundary overlap theo thuật toán trên\n",
        "    filter_iou = np.array(class_probs_filtered > 0.0, dtype='bool')\n",
        "    boxes_filtered = boxes_filtered[filter_iou]\n",
        "    class_probs_filtered = class_probs_filtered[filter_iou]\n",
        "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
        "\n",
        "    result = []\n",
        "    for i in range(len(boxes_filtered)):\n",
        "        result.append(\n",
        "            [classes_num_filtered[i],\n",
        "             boxes_filtered[i][0],\n",
        "             boxes_filtered[i][1],\n",
        "             boxes_filtered[i][2],\n",
        "             boxes_filtered[i][3],\n",
        "             class_probs_filtered[i]])\n",
        "\n",
        "    return result\n",
        "\n",
        "def draw_result(img, result):\n",
        "    \"\"\" hiển thị kết quả dự đoán\n",
        "    Args:\n",
        "      img: ảnh      \n",
        "      result: giá trị sinh ra ở hàm trên    \n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,10), dpi=40)\n",
        "    img = np.pad(img, [(50,50), (50,50), (0,0)], mode='constant', constant_values=255)\n",
        "    for i in range(len(result)):\n",
        "        x = int(result[i][1])+50\n",
        "        y = int(result[i][2])+50\n",
        "        w = int(result[i][3] / 2)\n",
        "        h = int(result[i][4] / 2)\n",
        "        cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (231, 76, 60), 2)\n",
        "        cv2.rectangle(img, (x - w, y - h - 20),\n",
        "                      (x -w + 50, y - h), (46, 204, 113), -1)\n",
        "        cv2.putText(\n",
        "            img, '{} : {:.2f}'.format(result[i][0] ,result[i][5]),\n",
        "            (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
        "            (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHWSPeCOavSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_idx = 3\n",
        "result = interpret_output(val_predict_object[img_idx], val_predict_class[img_idx], val_predict_normalized_box[img_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snEPC8O6kmyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "b13f0b8a-b171-4320-ff34-db57f76e2e1d"
      },
      "source": [
        "val_predict_object[3]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 6.24652579e-03,  6.11737370e-03],\n",
              "        [-8.81219003e-03,  7.43995786e-01],\n",
              "        [ 1.18483370e-02, -6.77257776e-05],\n",
              "        [ 3.81320063e-03,  1.27553195e-02],\n",
              "        [ 4.09629289e-03,  1.20367408e-02],\n",
              "        [ 1.92030810e-03,  2.14845091e-02],\n",
              "        [-3.28249182e-04,  1.04168132e-02]],\n",
              "\n",
              "       [[ 1.59328692e-02,  7.05288529e-01],\n",
              "        [ 7.53263664e-03,  4.77381311e-02],\n",
              "        [ 1.08497767e-02,  1.13246217e-02],\n",
              "        [-1.27782754e-03, -3.25215310e-02],\n",
              "        [ 9.78754018e-04,  1.93415582e-03],\n",
              "        [ 1.67507783e-03,  1.98413730e-02],\n",
              "        [ 3.36482655e-03,  8.40470940e-03]],\n",
              "\n",
              "       [[ 8.45606904e-03,  1.48212016e-02],\n",
              "        [-6.61837542e-03, -2.96047479e-02],\n",
              "        [ 1.46621447e-02,  3.05443183e-02],\n",
              "        [-4.54575382e-03,  8.61204863e-01],\n",
              "        [ 9.46774264e-04, -3.02757099e-02],\n",
              "        [ 2.71436851e-03,  1.07982606e-02],\n",
              "        [ 3.44984885e-03,  1.03361085e-02]],\n",
              "\n",
              "       [[ 1.17720442e-03,  1.37911141e-02],\n",
              "        [-2.54069753e-02,  7.91619658e-01],\n",
              "        [ 3.07246763e-03,  4.63303253e-02],\n",
              "        [ 3.10466532e-03,  5.26561290e-02],\n",
              "        [ 1.02615254e-02,  1.49098039e-02],\n",
              "        [-1.15009840e-04,  1.30141675e-02],\n",
              "        [ 3.33476719e-03,  1.01325959e-02]],\n",
              "\n",
              "       [[ 3.28568649e-03,  1.53330266e-02],\n",
              "        [-5.75438957e-04,  3.38650867e-02],\n",
              "        [ 1.84584141e-03,  1.54520273e-02],\n",
              "        [ 4.74811438e-03,  2.88163796e-02],\n",
              "        [ 2.87153432e-03,  3.76338959e-02],\n",
              "        [ 1.29268703e-03,  2.49082893e-02],\n",
              "        [ 2.90416460e-03,  9.18177515e-03]],\n",
              "\n",
              "       [[ 1.11408653e-02,  1.78903490e-02],\n",
              "        [-7.52195530e-03,  9.67912748e-02],\n",
              "        [-4.09288052e-03,  4.25822288e-03],\n",
              "        [ 6.38356991e-03,  8.40030611e-03],\n",
              "        [ 1.36996545e-02,  9.00819540e-01],\n",
              "        [ 2.97702104e-03, -1.06993318e-02],\n",
              "        [ 2.01206375e-03,  1.60039365e-02]],\n",
              "\n",
              "       [[ 1.30901230e-04,  1.46875978e-02],\n",
              "        [-4.09029704e-03,  7.85672784e-01],\n",
              "        [ 1.09929510e-03,  1.38528273e-02],\n",
              "        [ 6.63228240e-03, -1.53965503e-03],\n",
              "        [-1.68880932e-02,  7.34965205e-02],\n",
              "        [ 3.23206838e-03,  1.01281554e-02],\n",
              "        [ 3.55686713e-03,  9.17594135e-03]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU4bbZcJazdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_result(val_X_batch[img_idx]*255, result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGaokkiBbBG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}